[
  {
    "url": "https://api.github.com/repos/reactor/reactor-pool/issues/289",
    "repository_url": "https://api.github.com/repos/reactor/reactor-pool",
    "labels_url": "https://api.github.com/repos/reactor/reactor-pool/issues/289/labels{/name}",
    "comments_url": "https://api.github.com/repos/reactor/reactor-pool/issues/289/comments",
    "events_url": "https://api.github.com/repos/reactor/reactor-pool/issues/289/events",
    "html_url": "https://github.com/reactor/reactor-pool/issues/289",
    "id": 2976787220,
    "node_id": "I_kwDOCSkI0M6xbisU",
    "number": 289,
    "title": "[BUG] Metric `PENDING_CONNECTIONS_TIME` does not work as expected",
    "user": {
      "login": "mateusz-nalepa",
      "id": 24458964,
      "node_id": "MDQ6VXNlcjI0NDU4OTY0",
      "avatar_url": "https://avatars.githubusercontent.com/u/24458964?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mateusz-nalepa",
      "html_url": "https://github.com/mateusz-nalepa",
      "followers_url": "https://api.github.com/users/mateusz-nalepa/followers",
      "following_url": "https://api.github.com/users/mateusz-nalepa/following{/other_user}",
      "gists_url": "https://api.github.com/users/mateusz-nalepa/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mateusz-nalepa/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mateusz-nalepa/subscriptions",
      "organizations_url": "https://api.github.com/users/mateusz-nalepa/orgs",
      "repos_url": "https://api.github.com/users/mateusz-nalepa/repos",
      "events_url": "https://api.github.com/users/mateusz-nalepa/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mateusz-nalepa/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 1096290892,
        "node_id": "MDU6TGFiZWwxMDk2MjkwODky",
        "url": "https://api.github.com/repos/reactor/reactor-pool/labels/type/bug",
        "name": "bug",
        "color": "d4c5f9",
        "default": false,
        "description": "A general bug"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2025-04-01T23:19:06Z",
    "updated_at": "2025-04-29T21:35:11Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "<!--- Provide a general summary of the issue in the title above -->\n\n<!-- Make sure you use supported version\nhttps://github.com/reactor/.github/blob/main/SUPPORT.adoc#support-timeline\n-->\n\n<!--- /!\\ Make sure to follow the Contribution Guidelines and notably for security issues:\nhttps://github.com/reactor/.github/blob/main/CONTRIBUTING.md\nhttps://projectreactor.io/security-policy\n-->\n<!--- /!\\ Questions should be asked on [Gitter](https://gitter.im/reactor/reactor-netty) or [StackOverflow](https://stackoverflow.com/questions/tagged/reactor-netty). -->\n\n## Current situation compared to restaurant\nLet's imagine first, that we are going to restaurant. \nIt will be in my opinion, much easier to understand what is happening.\n\n#### Scenario A\nThere are: \n- 10 tables at the restaurant \n- 10 waiters\n- 15 guests\n- serving time is 5 minut\n\nIn that case, metrics \n`reactor.netty.resources.ConnectionProviderMeters#PENDING_CONNECTIONS_TIME` will be invoked only for 5 guests. And it will show 5 minutes.  Cause first 10 guests are not waiting. \n\n#### Scenario B\nThere are: \n- 10 tables at the restaurant \n- 10 waiters, `but all of them are busy and no one can handle guests, it will take them like 3 minutes to be available`\n- 7 guests\n- serving time is 5 minut\n\nIn that case, metrics \n`reactor.netty.resources.ConnectionProviderMeters#PENDING_CONNECTIONS_TIME` won't be invoked at all. And we are blind, cause guests are frustrated and we don't even have metric for them. They are already waiting 3 minutes, but we are telling them, that they weren't waiting at all. Cuase the waiters were too busy and didn't even notice, that someone is waiting.\n\n\n## Expected Behavior\n<!--- Tell us what you think should happen. -->\nMethod: `reactor.netty.internal.shaded.reactor.pool.AbstractPool.Borrower#stopPendingCountdown` should: \n\n- be renamed to `stopMeasuringLatency`\n- should measure the whole latency\n\n\n## Actual Behavior\nStatement `if (idle + estimatePermitCount < postOffer) {` from `SimpleDequePool` is invoked, only, when guests are waiting before the restaurant and all of the tables are busy.\n\n## Steps to Reproduce\n<!--- Provide a link to a live example, or an unambiguous set of steps to\nreproduce this bug, eg. a unit test. Include code to reproduce, if relevant.\nhttps://stackoverflow.com/help/minimal-reproducible-example -->\n\n\nExecute tests from class from reproducible example. It could be more minimal, but I've tried to make something close to real life scenario.\n\nThere are two tests cases in the class in which i've tried as much as I can to reproduce case with restaurant.\n\nhttps://github.com/mateusz-nalepa/spring-publishon/blob/main/app/src/test/kotlin/com/nalepa/publishon/WaitTimeInQueueEndpointTest.kt\n\n## Possible Solution\n<!--- Not obligatory, but you can suggest a fix/reason for the bug. -->\nAs a side effect of this issue, code can be simpler due to fact, that:\n  - statement `if (idle + estimatePermitCount < postOffer) {` could be removed from `SimpleDequePool`\n  - line `pending.pendingAcquireStart = this.clock.millis();` could be moved to `reactor.netty.internal.shaded.reactor.pool.AbstractPool.Borrower`\n\n## Your Environment\n<!--- Include as many relevant details about the environment you experienced the bug in. -->\n<!--- Especially, always include the version(s) of Reactor library/libraries you used! -->\n\n`reactor-netty-core`: \n\n* Reactor version(s) used: 1.2.4\n* Other relevant libraries versions (eg. `netty`, ...): `reactor-netty-core`: 1.2.4\n* JVM version (`java -version`): Java 21\n* OS and version (eg. `uname -a`): Darwin air-mateusz.home 21.6.0 Darwin Kernel Version 21.6.0: Sat Jun 18 17:07:28 PDT 2022; root:xnu-8020.140.41~1/RELEASE_ARM64_T8110 arm64\n\nPlease correct if I'm wrong with something, i would be glad to hear it! ‚ù§",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/reactor/reactor-pool/issues/289/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/reactor/reactor-pool/issues/289/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/reactor/reactor-pool/issues/285",
    "repository_url": "https://api.github.com/repos/reactor/reactor-pool",
    "labels_url": "https://api.github.com/repos/reactor/reactor-pool/issues/285/labels{/name}",
    "comments_url": "https://api.github.com/repos/reactor/reactor-pool/issues/285/comments",
    "events_url": "https://api.github.com/repos/reactor/reactor-pool/issues/285/events",
    "html_url": "https://github.com/reactor/reactor-pool/issues/285",
    "id": 2889103832,
    "node_id": "I_kwDOCSkI0M6sNDnY",
    "number": 285,
    "title": "Allow POOLABLE health check verifications",
    "user": {
      "login": "markitovtr1",
      "id": 2931989,
      "node_id": "MDQ6VXNlcjI5MzE5ODk=",
      "avatar_url": "https://avatars.githubusercontent.com/u/2931989?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/markitovtr1",
      "html_url": "https://github.com/markitovtr1",
      "followers_url": "https://api.github.com/users/markitovtr1/followers",
      "following_url": "https://api.github.com/users/markitovtr1/following{/other_user}",
      "gists_url": "https://api.github.com/users/markitovtr1/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/markitovtr1/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/markitovtr1/subscriptions",
      "organizations_url": "https://api.github.com/users/markitovtr1/orgs",
      "repos_url": "https://api.github.com/users/markitovtr1/repos",
      "events_url": "https://api.github.com/users/markitovtr1/events{/privacy}",
      "received_events_url": "https://api.github.com/users/markitovtr1/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 1096290894,
        "node_id": "MDU6TGFiZWwxMDk2MjkwODk0",
        "url": "https://api.github.com/repos/reactor/reactor-pool/labels/type/enhancement",
        "name": "type/enhancement",
        "color": "d4c5f9",
        "default": false,
        "description": "A general enhancement"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2025-03-01T19:22:14Z",
    "updated_at": "2025-03-17T12:28:12Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "I'm having some issues with r2dbc-pool and after much reading, I got to these issues:\n* [r2dbc-pool 187](https://github.com/r2dbc/r2dbc-pool/issues/187)\n* [reactor-pool 169](https://github.com/reactor/reactor-pool/issues/169)\n\nI think I have a better proposal here that would be great for this project.\n\n## Motivation\nreactor-pool supports lifecycle management for any POOLABLE object via time or size configurations, either life time, pool size or idle time.\n\nProblem is, for whatever reason, POOLABLE objects might be within healthy time parameters but become invalid. Let's say a connection that is supposed to be alive for 30s, but after 5s a problem in a node between source and target might make this connection invalid for both source and target. Database connections might suffer from these problems as well.\n\nIn these scenarios, r2dbc-pool `\"solves\"` this by adding a validation query that is executed right before returning a POOLABLE connection to a consumer. In case all connections became invalid, this would mean that a failure would invalidate entire pool and that would only be fixed when a connection is needed. In this scenario, pool consumer application would be hit with a acquire time penalty.\n\n## Desired solution\nPool should manage that POOLABLE objects are healthy and ready to be used by pool consumers. Besides eviction, I would like to have the ability to configure an `isHealthy` reactive predicates, `maxHealthTimeCheck` and also configure `healthCheckInterval`, much like background eviction intervals. In case an object is not healthy, it is removed from pool. \n\nAdditionally, I would like to configure a `healthCheckParallelCount` to maximize this validations and also that pool is smart enough to create new POOLABLE objects during these validations in case it would leave not enough connections in pool (e.g.: minIdle = 5 and healthCheckParallelCount = 3, it would need to create new 1 object if all objects are idle).\n\n## Considered alternatives\n1. Consume pool regularly to force object validations. Problem with this is I cannot access directly pool objects, so I could be checking the same object over and over again, without checking the rest of what is inside pool.\n2. Implement a custom object that keeps itself healthy and recovers itself This one almost works. Problem is in case it cannot recover itself and needs to be removed from pool because of an specific failure. In that scenario, it can't signal pool to be removed.\n\n## Additional context\nIn case this makes sense, I would love to discuss implementation details and try to submit a PR to address this myself, as I believe it would be a great addition to this project.\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/reactor/reactor-pool/issues/285/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/reactor/reactor-pool/issues/285/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/reactor/reactor-pool/issues/255",
    "repository_url": "https://api.github.com/repos/reactor/reactor-pool",
    "labels_url": "https://api.github.com/repos/reactor/reactor-pool/issues/255/labels{/name}",
    "comments_url": "https://api.github.com/repos/reactor/reactor-pool/issues/255/comments",
    "events_url": "https://api.github.com/repos/reactor/reactor-pool/issues/255/events",
    "html_url": "https://github.com/reactor/reactor-pool/issues/255",
    "id": 2727853738,
    "node_id": "I_kwDOCSkI0M6il76q",
    "number": 255,
    "title": "returnPermits exception stalls connection pool",
    "user": {
      "login": "erikbeerepoot",
      "id": 2739381,
      "node_id": "MDQ6VXNlcjI3MzkzODE=",
      "avatar_url": "https://avatars.githubusercontent.com/u/2739381?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/erikbeerepoot",
      "html_url": "https://github.com/erikbeerepoot",
      "followers_url": "https://api.github.com/users/erikbeerepoot/followers",
      "following_url": "https://api.github.com/users/erikbeerepoot/following{/other_user}",
      "gists_url": "https://api.github.com/users/erikbeerepoot/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/erikbeerepoot/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/erikbeerepoot/subscriptions",
      "organizations_url": "https://api.github.com/users/erikbeerepoot/orgs",
      "repos_url": "https://api.github.com/users/erikbeerepoot/repos",
      "events_url": "https://api.github.com/users/erikbeerepoot/events{/privacy}",
      "received_events_url": "https://api.github.com/users/erikbeerepoot/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 2,
    "created_at": "2024-12-09T17:54:36Z",
    "updated_at": "2025-01-17T22:13:35Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "<!--- Provide a general summary of the issue in the Title above -->\r\nWe are seeing an issue with `drainLoop` in `SimpleDequePool` that is similar to [this issue](https://github.com/reactor/reactor-pool/issues/118). We see the following pattern:\r\n1. Elevated errors over a period of hours (in our case, we see a high count of StackOverflowErrors). We are still attempting to understand the cause of these errors.\r\n2. We observe a `Too many permits returned` error in our logs. In our case, the connection pool is configured with 500 connections, so the error is `Too many permits returned: returned=1, would bring to 501/500.`.\r\n3. Idle an active connections go to 0 (observed via metrics) and pending connections continue to build (we've seen many thousands).\r\n4. No more outgoing request are observed.\r\n\r\nWe have manually attempted to reproduce this issue by implementing a custom AllocationStrategy that delegates to an actual allocation strategy but throws an exception in `returnPermits` (either randomly, or after a given number of calls). After this exception is thrown, we observe the same behaviour as above. We don't currently understand how reach a state where the `PERMITS` count is off (we are unable to enable DEBUG logging in production due to PII concerns, but are looking to deploy some changes that will add logging on the number of permits as well as the state of the connection pool. Any pointers you have would be appreciated).\r\n\r\nOne hypothesis is that [the exception is not handled](https://github.com/reactor/reactor-pool/blob/main/reactor-pool/src/main/java/reactor/pool/SimpleDequePool.java#L434), and WIP is not decremented. When [doAcquire() is called](https://github.com/reactor/reactor-pool/blob/main/reactor-pool/src/main/java/reactor/pool/SimpleDequePool.java#L295), [elements are added to the pending queue as before](https://github.com/reactor/reactor-pool/blob/main/reactor-pool/src/main/java/reactor/pool/SimpleDequePool.java#L579), but `drainLoop` cannot be entered as `WIP` will not be 0.\r\n\r\nAnother option is that it's hitting this exception in `destroyPoolable`.\r\n\r\n<!-- Make sure you use supported version\r\nhttps://github.com/reactor/.github/blob/main/SUPPORT.adoc#support-timeline\r\n-->\r\n\r\n<!--- /!\\ Make sure to follow the Contribution Guidelines, notably for security issues and questions:\r\nhttps://github.com/reactor/.github/blob/main/CONTRIBUTING.md\r\nhttps://projectreactor.io/security-policy\r\nhttps://github.com/reactor/.github/blob/main/CONTRIBUTING.md#question-do-you-have-a-question\r\n-->\r\n\r\n## Expected Behavior\r\n<!--- Tell us what you think should happen. -->\r\nIdeally, the connection pool would continue to function. I don't know if that is realistic given that PERMITS would continue to be wrong.\r\n\r\n## Actual Behavior\r\n<!--- Tell us what happens instead of the expected behavior. -->\r\nNo more connections are made.\r\n\r\n## Steps to Reproduce\r\n<!---Provide a link to a live example, or an unambiguous set of steps to\r\nreproduce this bug, eg. a unit test. Include code to reproduce, if relevant.\r\nMost projects use JUnit5 now (like in snippet below; otherwise use JUnit4).\r\n-->\r\n\r\nWe realize this is a contrived example, but matches what we end up seeing in production.\r\n\r\n```java\r\nclass ThrowingAllocationStrategy(...) {\r\n    private val allocationStrategyDelegate = // your actually, allocation strategy here, eg. Http2AllocationStrategy, SizeBasedAllocationStrategy\r\n    // implement the remainder by just delegating the calls to the underlying allocation strategy\r\n\r\n    override fun returnPermits(p0: Int) {\r\n        randomlyThrow()\r\n\r\n        allocationStrategyDelegate.returnPermits(p0)\r\n    }\r\n\r\n    private fun randomlyThrow() {\r\n        if (Random.nextInt(100) == 0) {\r\n            throw RuntimeException(\"Boom!\")\r\n        }\r\n    }\r\n}\r\n\r\n<SNIP>\r\n// init custom connection provider with the custom allocation strategy\r\nreturn ConnectionProvider\r\n        .allocationStrategy(loggingAllocationStrategy!!)\r\n        .build()\r\n  \r\n```\r\n\r\n## Possible Solution\r\nGiven the the PERMITS count is off, it's unclear to me what the proper resolution would be. We noticed that disposing of the connection provider did resolve the issue as expected, presumably because the connection pool would be fresh and not in a bad state. I'm not sure what the implications would be of continuing to use the existing connection pool, as I would expect to see the permits exception being thrown repeatedly.\r\n\r\n## Your Environment\r\n<!--- Include as many relevant details about the environment you experienced the bug in. -->\r\n<!--- Especially, always include the version(s) of Reactor library/libraries you used! -->\r\n\r\n```\r\nreactor-pool == 0.2.13\r\nio.projectreactor:reactor-core:3.5.20 -> 3.6.9\r\norg.springframework:spring-webflux -> 6.1.12\r\nio.projectreactor.netty:reactor-netty-core:1.1.22\r\nnetty:4.1.112.Final\r\n```\r\nAlso tried the latest main commit for reactor-core and reactor-pool.\r\n* Other relevant libraries versions (eg. `netty`, ...): netty, netty == 4.1.x, \r\n* JVM version (`java -version`): 21, 17.\r\n* OS and version (eg `uname -a`): \r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/reactor/reactor-pool/issues/255/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/reactor/reactor-pool/issues/255/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/reactor/reactor-pool/issues/179",
    "repository_url": "https://api.github.com/repos/reactor/reactor-pool",
    "labels_url": "https://api.github.com/repos/reactor/reactor-pool/issues/179/labels{/name}",
    "comments_url": "https://api.github.com/repos/reactor/reactor-pool/issues/179/comments",
    "events_url": "https://api.github.com/repos/reactor/reactor-pool/issues/179/events",
    "html_url": "https://github.com/reactor/reactor-pool/pull/179",
    "id": 2011190807,
    "node_id": "PR_kwDOCSkI0M5gYb_a",
    "number": 179,
    "title": "Concurrent Reactor Pools",
    "user": {
      "login": "pderop",
      "id": 650758,
      "node_id": "MDQ6VXNlcjY1MDc1OA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/650758?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/pderop",
      "html_url": "https://github.com/pderop",
      "followers_url": "https://api.github.com/users/pderop/followers",
      "following_url": "https://api.github.com/users/pderop/following{/other_user}",
      "gists_url": "https://api.github.com/users/pderop/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/pderop/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/pderop/subscriptions",
      "organizations_url": "https://api.github.com/users/pderop/orgs",
      "repos_url": "https://api.github.com/users/pderop/repos",
      "events_url": "https://api.github.com/users/pderop/events{/privacy}",
      "received_events_url": "https://api.github.com/users/pderop/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 1096290894,
        "node_id": "MDU6TGFiZWwxMDk2MjkwODk0",
        "url": "https://api.github.com/repos/reactor/reactor-pool/labels/type/enhancement",
        "name": "type/enhancement",
        "color": "d4c5f9",
        "default": false,
        "description": "A general enhancement"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": {
      "login": "pderop",
      "id": 650758,
      "node_id": "MDQ6VXNlcjY1MDc1OA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/650758?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/pderop",
      "html_url": "https://github.com/pderop",
      "followers_url": "https://api.github.com/users/pderop/followers",
      "following_url": "https://api.github.com/users/pderop/following{/other_user}",
      "gists_url": "https://api.github.com/users/pderop/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/pderop/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/pderop/subscriptions",
      "organizations_url": "https://api.github.com/users/pderop/orgs",
      "repos_url": "https://api.github.com/users/pderop/repos",
      "events_url": "https://api.github.com/users/pderop/events{/privacy}",
      "received_events_url": "https://api.github.com/users/pderop/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "assignees": [
      {
        "login": "pderop",
        "id": 650758,
        "node_id": "MDQ6VXNlcjY1MDc1OA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/650758?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/pderop",
        "html_url": "https://github.com/pderop",
        "followers_url": "https://api.github.com/users/pderop/followers",
        "following_url": "https://api.github.com/users/pderop/following{/other_user}",
        "gists_url": "https://api.github.com/users/pderop/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/pderop/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/pderop/subscriptions",
        "organizations_url": "https://api.github.com/users/pderop/orgs",
        "repos_url": "https://api.github.com/users/pderop/repos",
        "events_url": "https://api.github.com/users/pderop/events{/privacy}",
        "received_events_url": "https://api.github.com/users/pderop/received_events",
        "type": "User",
        "user_view_type": "public",
        "site_admin": false
      }
    ],
    "milestone": null,
    "comments": 5,
    "created_at": "2023-11-26T20:21:22Z",
    "updated_at": "2024-08-26T08:34:31Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "draft": true,
    "pull_request": {
      "url": "https://api.github.com/repos/reactor/reactor-pool/pulls/179",
      "html_url": "https://github.com/reactor/reactor-pool/pull/179",
      "diff_url": "https://github.com/reactor/reactor-pool/pull/179.diff",
      "patch_url": "https://github.com/reactor/reactor-pool/pull/179.patch",
      "merged_at": null
    },
    "body": "This PR introduces a new feature for the Reactor Pool, aimed at preventing resource starvation in highly concurrent scenarios. Currently, when multiple threads simultaneously acquire and release resources, the SimpleDequeuePool's `drainLoop` method can monopolize a CPU core, causing a bottleneck where other threads may remain less utilized.\r\n\r\nThere are of course existing ways to prevent one thread being executing the drainLoop method for a too long time, one can for instance use an `acquisition scheduler`, in order to offload borrowers delivery using a configured scheduler, at the cost of using extra threads. \r\n\r\nThis PR experiments another way to offload the delivery of borrowers. Instead of using an acquisition scheduler, a concurrent `InstrumentedPoolDecorator` can be used. it allows to create a pool composed of multiple sub pools, each managing a portion of resources. Application Executors (i.e Netty Event Loops for example) can then be reused and  assigned to each sub pools, where acquisitions tasks will be scheduled. No extra threads will be created. This design enables concurrent distribution of resource acquisitions across these sub-pools, using a work-stealing approach where a busy sub-pool can be helped by another free sub-pool, which can steal acquisition tasks from the busy sub-pool.\r\n\r\nFor instance, in Reactor Netty, each Netty Event Loop thread will have its sub-pool with its assigned HTTP/2 connection resources.\r\n\r\nThe work is still in progress (even I'm not sure about the API), some issues remain and **this PR could be merged in a temporary branch**, in order to make it easier to continue the work on it. I don't have created a branch for the moment, to be confirmed by the Reactor team.\r\n\r\nAttached to this PR a JMH project which compares the different approaches. The `WorkStealingPoolBenchmark`simulates a netty application which run hundreds of thousands of tasks running within an EventLoop Group. Each task will then acquire and release some resources. The benchmark needs this PR to be compiled and installed in local M2.\r\n\r\nSee attached \r\n[reactor-pool-jmh.tgz](https://github.com/reactor/reactor-pool/files/13902434/reactor-pool-jmh.tgz)\r\n\r\n\r\nIn the  WorkStealingPoolBenchmark class:\r\n\r\n- benchWithSimplePool: this method simulates activities that are running within a Netty EventLoop group. So tasks are scheduled in Event Loops, each one is then acquiring/releasing a `PiCalculator` resources. When a  task has acquired a PICalculator, the PI number is computed, and the PiCalculator is then returned to the pool. When running this method, there will be actually one single running thread: it will be the one that is running the drainLoop method, which will spend it's life delivering \"PiCalculator\" resources to all borrowers from all event loop threads. Since no acquisition scheduler is used, the drainLoop is then consuming one core forever, and other tasks are just scheduling acquisition tasks to the pool. Check with Top, the process only consume 125% of total CPUs. The test runs in about 18 seconds on a Mac M1 with 10 cpus.\r\n\r\n- benchWithAcquisitionSchedulerEventLoop: this benchmark tries to avoid the starvation problem by using an acquisition scheduler, where all borrowers are then delivered using the EventLoopGroup of the simulated application. This significantly improves performance (see below the results: about 10.78 secs).\r\n\r\n- benchWithAcquisitionSchedulerFJP: this time, the common system ForkJoinPool is used to offload deliveries of borrowers. This improves even more performances, at the cost of using extra threads (in Reactor Netty, idealy, for example, we would like to avoid using extra threads, only the event loop threads ...): 5.11 sec.\r\n\r\n- finally, the benchWithConcurrentPools method is doing a benchmark with this PR: a \"concurrent\" InstrumentedPool, composed of multiple sub pools, each one assigned to each Event Loop Executors: 2.75 sec.\r\n\r\nThe results are the following (tested with JDK 21):\r\n(lesser score is better)\r\n\r\n```\r\nBenchmark                                                         Mode  Cnt  Score   Error  Units\r\nWorkStealingPoolBenchmark.benchWithAcquisitionSchedulerEventLoop  avgt       1.222           s/op\r\nWorkStealingPoolBenchmark.benchWithAcquisitionSchedulerFJP        avgt       1.239           s/op\r\nWorkStealingPoolBenchmark.benchWithConcurrentPools                avgt       0.894           s/op\r\nWorkStealingPoolBenchmark.benchWithSimplePool                     avgt       6.612           s/op\r\n```\r\n\r\nRemaining issues:\r\n\r\n- The WorkStealingPool is not implementing any idle resource reuse LRU or MRU order configured via PoolBuilder.idleResourceReuseLruOrder or PoolBuilder.idleResourceReuseMruOrder. Only the sub-pools implement the configured idle resource reuse strategy. I actually wonder how this could be implemented globally on top of all sub pools.\r\n- Metrics are implemented naively, by iterating over all sub pools. Common metrics with some long adders should be shared between all sub pools !\r\n- The WorkStealingPool config() method is currently returning the config of the first sub-pool, this is questionable ... maybe a concurrent pool should be created using a PoolBuilder, so it can have its own config. Currently, the concurrent pool is created using `InstrumentedPoolDecorators.concurrentPools` factory method.\r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/reactor/reactor-pool/issues/179/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/reactor/reactor-pool/issues/179/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/reactor/reactor-pool/issues/170",
    "repository_url": "https://api.github.com/repos/reactor/reactor-pool",
    "labels_url": "https://api.github.com/repos/reactor/reactor-pool/issues/170/labels{/name}",
    "comments_url": "https://api.github.com/repos/reactor/reactor-pool/issues/170/comments",
    "events_url": "https://api.github.com/repos/reactor/reactor-pool/issues/170/events",
    "html_url": "https://github.com/reactor/reactor-pool/issues/170",
    "id": 1679358255,
    "node_id": "I_kwDOCSkI0M5kGPkv",
    "number": 170,
    "title": "Problems when warmup procedure and database query procedure running in parallel.",
    "user": {
      "login": "1528110566",
      "id": 36795226,
      "node_id": "MDQ6VXNlcjM2Nzk1MjI2",
      "avatar_url": "https://avatars.githubusercontent.com/u/36795226?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/1528110566",
      "html_url": "https://github.com/1528110566",
      "followers_url": "https://api.github.com/users/1528110566/followers",
      "following_url": "https://api.github.com/users/1528110566/following{/other_user}",
      "gists_url": "https://api.github.com/users/1528110566/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/1528110566/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/1528110566/subscriptions",
      "organizations_url": "https://api.github.com/users/1528110566/orgs",
      "repos_url": "https://api.github.com/users/1528110566/repos",
      "events_url": "https://api.github.com/users/1528110566/events{/privacy}",
      "received_events_url": "https://api.github.com/users/1528110566/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 2057670987,
        "node_id": "MDU6TGFiZWwyMDU3NjcwOTg3",
        "url": "https://api.github.com/repos/reactor/reactor-pool/labels/:question:need-triage",
        "name": ":question:need-triage",
        "color": "fbca04",
        "default": false,
        "description": "This issue needs triage, hasn't been looked at by a team member yet"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 0,
    "created_at": "2023-04-22T05:58:26Z",
    "updated_at": "2023-04-22T06:05:55Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "<!--- Provide a general summary of the issue in the Title above -->\r\n\r\nI want to warmup connection pool when the application start, and I want get some configs from database.\r\nSo I wrote this, `Test` is the name of database table.\r\n```java\r\n@Autowired\r\nprivate ConnectionPool connectionPool;\r\n@Autowired\r\nprivate R2dbcEntityTemplate r2dbcEntityTemplate;\r\n@PostConstruct\r\npublic void init() {\r\n    connectionPool.warmup().subscribe();\r\n    List<Test> block = r2dbcEntityTemplate.select(Test.class).all().collectList().block();\r\n    System.out.println(block);\r\n}\r\n```\r\n\r\n## Expected Behavior\r\nwarmup procedure and database query procedure running in parallel, and database query procedure will be waited until there is available connection to use.\r\n\r\n## Actual Behavior\r\ndatabase query procedure is stuck even if warmup procedure is complete.\r\n\r\n## Steps to Reproduce\r\npom.xml\r\n```xml\r\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\r\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\r\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\r\n    <parent>\r\n        <artifactId>spring-boot-starter-parent</artifactId>\r\n        <groupId>org.springframework.boot</groupId>\r\n        <version>2.5.13</version>\r\n    </parent>\r\n    <modelVersion>4.0.0</modelVersion>\r\n\r\n    <groupId>org.example</groupId>\r\n    <artifactId>r2dbc-demo</artifactId>\r\n    <version>1.0-SNAPSHOT</version>\r\n\r\n    <properties>\r\n        <maven.compiler.source>8</maven.compiler.source>\r\n        <maven.compiler.target>8</maven.compiler.target>\r\n    </properties>\r\n    <dependencies>\r\n        <dependency>\r\n            <groupId>org.projectlombok</groupId>\r\n            <artifactId>lombok</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.springframework.data</groupId>\r\n            <artifactId>spring-data-r2dbc</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>dev.miku</groupId>\r\n            <artifactId>r2dbc-mysql</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>io.r2dbc</groupId>\r\n            <artifactId>r2dbc-spi</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>io.r2dbc</groupId>\r\n            <artifactId>r2dbc-pool</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-webflux</artifactId>\r\n        </dependency>\r\n    </dependencies>\r\n</project>\r\n```\r\njava code\r\n```java\r\n@SpringBootApplication\r\n@EnableR2dbcRepositories\r\npublic class Application {\r\n\r\n    public static void main(String[] args) {\r\n        SpringApplication.run(Application.class, args);\r\n    }\r\n\r\n    @Autowired\r\n    private ConnectionPool connectionPool;\r\n    @Autowired\r\n    private R2dbcEntityTemplate r2dbcEntityTemplate;\r\n    @PostConstruct\r\n    public void init() {\r\n        connectionPool.warmup().subscribe();\r\n        List<Test> block = r2dbcEntityTemplate.select(Test.class).all().collectList().block();\r\n        System.out.println(block);\r\n    }\r\n}\r\n\r\n// 1 million records\r\n@Data\r\n@Table(\"test\")\r\npublic class Test {\r\n    @Id\r\n    private String name;\r\n}\r\n```\r\n\r\n\r\n## Possible Solution\r\nchange ` connectionPool.warmup().subscribe();` to ` connectionPool.warmup().block();`\r\nor\r\nadd `spring.r2dbc.pool.max-acquire-time: 7s`  in `application.yml`, after 7 seconds, database query procedure go on and no errors in log file.\r\n\r\n## Your Environment\r\n\r\n* Reactor version(s) used:  see `pom.xml` above\r\n* Other relevant libraries versions (eg. `netty`, ...):  Mysql-5.7.41-winx64\r\n* JVM version (`java -version`): jdk 1.8.0_162\r\n* OS and version (eg `uname -a`): windows11 22621.1555\r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/reactor/reactor-pool/issues/170/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/reactor/reactor-pool/issues/170/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/reactor/reactor-pool/issues/123",
    "repository_url": "https://api.github.com/repos/reactor/reactor-pool",
    "labels_url": "https://api.github.com/repos/reactor/reactor-pool/issues/123/labels{/name}",
    "comments_url": "https://api.github.com/repos/reactor/reactor-pool/issues/123/comments",
    "events_url": "https://api.github.com/repos/reactor/reactor-pool/issues/123/events",
    "html_url": "https://github.com/reactor/reactor-pool/issues/123",
    "id": 823184966,
    "node_id": "MDU6SXNzdWU4MjMxODQ5NjY=",
    "number": 123,
    "title": "maxPending limit is enforced with some de-facto leniency under heavy load",
    "user": {
      "login": "simonbasle",
      "id": 6986166,
      "node_id": "MDQ6VXNlcjY5ODYxNjY=",
      "avatar_url": "https://avatars.githubusercontent.com/u/6986166?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/simonbasle",
      "html_url": "https://github.com/simonbasle",
      "followers_url": "https://api.github.com/users/simonbasle/followers",
      "following_url": "https://api.github.com/users/simonbasle/following{/other_user}",
      "gists_url": "https://api.github.com/users/simonbasle/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/simonbasle/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/simonbasle/subscriptions",
      "organizations_url": "https://api.github.com/users/simonbasle/orgs",
      "repos_url": "https://api.github.com/users/simonbasle/repos",
      "events_url": "https://api.github.com/users/simonbasle/events{/privacy}",
      "received_events_url": "https://api.github.com/users/simonbasle/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 1096290894,
        "node_id": "MDU6TGFiZWwxMDk2MjkwODk0",
        "url": "https://api.github.com/repos/reactor/reactor-pool/labels/type/enhancement",
        "name": "type/enhancement",
        "color": "d4c5f9",
        "default": false,
        "description": "A general enhancement"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": {
      "url": "https://api.github.com/repos/reactor/reactor-pool/milestones/13",
      "html_url": "https://github.com/reactor/reactor-pool/milestone/13",
      "labels_url": "https://api.github.com/repos/reactor/reactor-pool/milestones/13/labels",
      "id": 5688752,
      "node_id": "MDk6TWlsZXN0b25lNTY4ODc1Mg==",
      "number": 13,
      "title": "Backburner",
      "description": null,
      "creator": {
        "login": "simonbasle",
        "id": 6986166,
        "node_id": "MDQ6VXNlcjY5ODYxNjY=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6986166?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/simonbasle",
        "html_url": "https://github.com/simonbasle",
        "followers_url": "https://api.github.com/users/simonbasle/followers",
        "following_url": "https://api.github.com/users/simonbasle/following{/other_user}",
        "gists_url": "https://api.github.com/users/simonbasle/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/simonbasle/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/simonbasle/subscriptions",
        "organizations_url": "https://api.github.com/users/simonbasle/orgs",
        "repos_url": "https://api.github.com/users/simonbasle/repos",
        "events_url": "https://api.github.com/users/simonbasle/events{/privacy}",
        "received_events_url": "https://api.github.com/users/simonbasle/received_events",
        "type": "User",
        "user_view_type": "public",
        "site_admin": false
      },
      "open_issues": 2,
      "closed_issues": 0,
      "state": "open",
      "created_at": "2020-07-22T09:46:19Z",
      "updated_at": "2024-06-03T09:20:47Z",
      "due_on": null,
      "closed_at": null
    },
    "comments": 4,
    "created_at": "2021-03-05T15:20:43Z",
    "updated_at": "2024-06-03T09:20:47Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "Follow-up to #121 and #122.\r\n\r\nWith #122, the situation has improved and `maxPending` cap should be enforced _with some leniency/margin of error_. It might accumulate pending `acquire` calls over the configured limit, but within acceptable bounds (under heavy load). Previously, under heavy load it would grow past the limit indefinitely.\r\n\r\nHowever, ideally the pool should manage to strictly enforce the `maxPending` limit.\r\nThis issue tracks that goal.",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/reactor/reactor-pool/issues/123/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/reactor/reactor-pool/issues/123/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/reactor/reactor-pool/issues/118",
    "repository_url": "https://api.github.com/repos/reactor/reactor-pool",
    "labels_url": "https://api.github.com/repos/reactor/reactor-pool/issues/118/labels{/name}",
    "comments_url": "https://api.github.com/repos/reactor/reactor-pool/issues/118/comments",
    "events_url": "https://api.github.com/repos/reactor/reactor-pool/issues/118/events",
    "html_url": "https://github.com/reactor/reactor-pool/issues/118",
    "id": 787744075,
    "node_id": "MDU6SXNzdWU3ODc3NDQwNzU=",
    "number": 118,
    "title": "WIP always above zero in SimpleDequePool ",
    "user": {
      "login": "machao23",
      "id": 5095336,
      "node_id": "MDQ6VXNlcjUwOTUzMzY=",
      "avatar_url": "https://avatars.githubusercontent.com/u/5095336?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/machao23",
      "html_url": "https://github.com/machao23",
      "followers_url": "https://api.github.com/users/machao23/followers",
      "following_url": "https://api.github.com/users/machao23/following{/other_user}",
      "gists_url": "https://api.github.com/users/machao23/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/machao23/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/machao23/subscriptions",
      "organizations_url": "https://api.github.com/users/machao23/orgs",
      "repos_url": "https://api.github.com/users/machao23/repos",
      "events_url": "https://api.github.com/users/machao23/events{/privacy}",
      "received_events_url": "https://api.github.com/users/machao23/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 1096290892,
        "node_id": "MDU6TGFiZWwxMDk2MjkwODky",
        "url": "https://api.github.com/repos/reactor/reactor-pool/labels/type/bug",
        "name": "bug",
        "color": "d4c5f9",
        "default": false,
        "description": "A general bug"
      },
      {
        "id": 1323599754,
        "node_id": "MDU6TGFiZWwxMzIzNTk5NzU0",
        "url": "https://api.github.com/repos/reactor/reactor-pool/labels/for/user-attention",
        "name": "for/user-attention",
        "color": "c5def5",
        "default": false,
        "description": "This issue needs user attention (feedback, rework, etc...)"
      },
      {
        "id": 1481553054,
        "node_id": "MDU6TGFiZWwxNDgxNTUzMDU0",
        "url": "https://api.github.com/repos/reactor/reactor-pool/labels/status/need-investigation",
        "name": "status/need-investigation",
        "color": "fef2c0",
        "default": false,
        "description": "This needs more in-depth investigation"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": null,
    "comments": 24,
    "created_at": "2021-01-17T16:39:16Z",
    "updated_at": "2024-05-16T13:18:57Z",
    "closed_at": null,
    "author_association": "NONE",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "I'm using reactor-netty to make API calls and facing an issue wherein reactor-netty is not able to create new connections for the incoming requests. And I debuged codes and found the result of `WIP.getAndIncrement(this)` always above zero.\r\n\r\n## Expected Behavior\r\nEven if the `drainLoop` is broken by some requests, it shouldn't affect further requests.\r\n\r\n## Actual Behavior\r\nThe `darainLoop` never called anymore after some exceptions occurred.\r\n\r\n## Steps to Reproduce\r\nUnfortunately, I don't know how to reproduce this because I don't know the root cause.\r\nIf this helps in any manner, I checked the logs on prod and there're some exceptions occurred during `drainLoop`:\r\n```\r\nFailed to mark a promise as failure because it has failed already: DefaultChannelPromise@5a854314(failure: io.netty.handler.codec.EncoderException: io.netty.util.IllegalReferenceCountException: refCnt: 0, decrement: 1), unnotified cause: io.netty.handler.codec.EncoderException: io.netty.util.IllegalReferenceCountException: refCnt: 0, decrement: 1\r\n\tat io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:104)\r\n\tat io.netty.channel.CombinedChannelDuplexHandler.write(CombinedChannelDuplexHandler.java:346)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:709)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:792)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:702)\r\n\tat io.netty.handler.timeout.IdleStateHandler.write(IdleStateHandler.java:304)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:709)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:792)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:702)\r\n\tat io.netty.handler.timeout.WriteTimeoutHandler.write(WriteTimeoutHandler.java:112)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:790)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:758)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:808)\r\n\tat io.netty.channel.DefaultChannelPipeline.writeAndFlush(DefaultChannelPipeline.java:1025)\r\n\tat io.netty.channel.AbstractChannel.writeAndFlush(AbstractChannel.java:294)\r\n\tat reactor.netty.http.HttpOperations.lambda$send$0(HttpOperations.java:123)\r\n\tat reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:151)\r\n\tat reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53)\r\n\tat reactor.core.publisher.Mono.subscribe(Mono.java:4198)\r\n\tat reactor.netty.NettyOutbound.subscribe(NettyOutbound.java:336)\r\n\tat reactor.core.publisher.MonoSource.subscribe(MonoSource.java:65)\r\n\tat reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:52)\r\n\tat reactor.netty.http.client.HttpClientConnect$HttpIOHandlerObserver.onStateChange(HttpClientConnect.java:446)\r\n\tat reactor.netty.ReactorNetty$CompositeConnectionObserver.onStateChange(ReactorNetty.java:518)\r\n\tat reactor.netty.resources.PooledConnectionProvider$DisposableAcquire.run(PooledConnectionProvider.java:633)\r\n\tat reactor.netty.resources.PooledConnectionProvider$DisposableAcquire.onNext(PooledConnectionProvider.java:506)\r\n\tat reactor.netty.resources.PooledConnectionProvider$DisposableAcquire.onNext(PooledConnectionProvider.java:457)\r\n\tat reactor.netty.internal.shaded.reactor.pool.AbstractPool$Borrower.deliver(AbstractPool.java:419)\r\n\tat reactor.netty.internal.shaded.reactor.pool.SimpleDequePool.lambda$drainLoop$15(SimpleDequePool.java:391)\r\n\tat reactor.core.scheduler.ImmediateScheduler.schedule(ImmediateScheduler.java:47)\r\n\tat reactor.netty.internal.shaded.reactor.pool.SimpleDequePool.drainLoop(SimpleDequePool.java:391)\r\n\tat reactor.netty.internal.shaded.reactor.pool.SimpleDequePool.drain(SimpleDequePool.java:261)\r\n\tat reactor.netty.internal.shaded.reactor.pool.SimpleDequePool.doAcquire(SimpleDequePool.java:256)\r\n\tat reactor.netty.internal.shaded.reactor.pool.AbstractPool$Borrower.request(AbstractPool.java:382)\r\n\tat reactor.netty.resources.PooledConnectionProvider$DisposableAcquire.onSubscribe(PooledConnectionProvider.java:532)\r\n\tat reactor.netty.internal.shaded.reactor.pool.SimpleDequePool$QueueBorrowerMono.subscribe(SimpleDequePool.java:578)\r\n\tat reactor.netty.resources.PooledConnectionProvider.disposableAcquire(PooledConnectionProvider.java:218)\r\n\tat reactor.netty.resources.PooledConnectionProvider.lambda$acquire$3(PooledConnectionProvider.java:182)\r\n\tat reactor.core.publisher.MonoCreate.subscribe(MonoCreate.java:57)\r\n\tat reactor.netty.http.client.HttpClientConnect$MonoHttpConnect.lambda$subscribe$0(HttpClientConnect.java:327)\r\n\tat reactor.core.publisher.MonoCreate.subscribe(MonoCreate.java:57)\r\n\tat reactor.core.publisher.FluxRetryWhen$RetryWhenMainSubscriber.resubscribe(FluxRetryWhen.java:204)\r\n\tat reactor.core.publisher.FluxRetryWhen$RetryWhenOtherSubscriber.onNext(FluxRetryWhen.java:250)\r\n\tat reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.innerNext(FluxConcatMap.java:274)\r\n\tat reactor.core.publisher.FluxConcatMap$ConcatMapInner.onNext(FluxConcatMap.java:851)\r\n\tat reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1782)\r\n\tat reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:241)\r\n\tat reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1782)\r\n\tat reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.drain(MonoIgnoreThen.java:147)\r\n\tat reactor.core.publisher.MonoIgnoreThen.subscribe(MonoIgnoreThen.java:56)\r\n\tat reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:150)\r\n\tat reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1782)\r\n\tat reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.drain(MonoIgnoreThen.java:147)\r\n\tat reactor.core.publisher.MonoIgnoreThen.subscribe(MonoIgnoreThen.java:56)\r\n\tat reactor.core.publisher.Mono.subscribe(Mono.java:4213)\r\n\tat reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.drain(FluxConcatMap.java:441)\r\n\tat reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.onNext(FluxConcatMap.java:243)\r\n\tat reactor.core.publisher.DirectProcessor$DirectInner.onNext(DirectProcessor.java:333)\r\n\tat reactor.core.publisher.DirectProcessor.onNext(DirectProcessor.java:142)\r\n\tat reactor.core.publisher.SerializedSubscriber.onNext(SerializedSubscriber.java:99)\r\n\tat reactor.core.publisher.FluxRetryWhen$RetryWhenMainSubscriber.onError(FluxRetryWhen.java:180)\r\n\tat reactor.core.publisher.MonoCreate$DefaultMonoSink.error(MonoCreate.java:185)\r\n\tat reactor.netty.http.client.HttpClientConnect$HttpObserver.onUncaughtException(HttpClientConnect.java:407)\r\n\tat reactor.netty.ReactorNetty$CompositeConnectionObserver.onUncaughtException(ReactorNetty.java:511)\r\n\tat reactor.netty.resources.PooledConnectionProvider$DisposableAcquire.onUncaughtException(PooledConnectionProvider.java:549)\r\n\tat reactor.netty.resources.PooledConnectionProvider$PooledConnection.onUncaughtException(PooledConnectionProvider.java:385)\r\n\tat reactor.netty.channel.FluxReceive.drainReceiver(FluxReceive.java:230)\r\n\tat reactor.netty.channel.FluxReceive.onInboundError(FluxReceive.java:435)\r\n\tat reactor.netty.channel.ChannelOperations.onInboundError(ChannelOperations.java:442)\r\n\tat reactor.netty.channel.ChannelOperationsHandler.exceptionCaught(ChannelOperationsHandler.java:129)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:302)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:281)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:273)\r\n\tat io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireExceptionCaught(CombinedChannelDuplexHandler.java:424)\r\n\tat io.netty.channel.ChannelHandlerAdapter.exceptionCaught(ChannelHandlerAdapter.java:92)\r\n\tat io.netty.channel.CombinedChannelDuplexHandler$1.fireExceptionCaught(CombinedChannelDuplexHandler.java:145)\r\n\tat io.netty.channel.ChannelInboundHandlerAdapter.exceptionCaught(ChannelInboundHandlerAdapter.java:143)\r\n\tat io.netty.channel.CombinedChannelDuplexHandler.exceptionCaught(CombinedChannelDuplexHandler.java:231)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:302)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:281)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:273)\r\n\tat io.netty.handler.ssl.SslHandler.exceptionCaught(SslHandler.java:1144)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:302)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:281)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:273)\r\n\tat io.netty.handler.proxy.ProxyHandler.exceptionCaught(ProxyHandler.java:241)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:302)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:281)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:273)\r\n\tat io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireExceptionCaught(CombinedChannelDuplexHandler.java:424)\r\n\tat io.netty.channel.CombinedChannelDuplexHandler$1.fireExceptionCaught(CombinedChannelDuplexHandler.java:161)\r\n\tat io.netty.channel.CombinedChannelDuplexHandler.exceptionCaught(CombinedChannelDuplexHandler.java:233)\r\n\tat io.netty.handler.proxy.HttpProxyHandler$HttpClientCodecWrapper.exceptionCaught(HttpProxyHandler.java:247)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:302)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:281)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:273)\r\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.exceptionCaught(DefaultChannelPipeline.java:1377)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:302)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:281)\r\n\tat io.netty.channel.DefaultChannelPipeline.fireExceptionCaught(DefaultChannelPipeline.java:907)\r\n\tat io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.handleReadException(AbstractEpollStreamChannel.java:728)\r\n\tat io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:818)\r\n\tat io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:475)\r\n\tat io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:378)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\r\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\r\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\r\n\tat java.base/java.lang.Thread.run(Thread.java:834)\r\nCaused by: io.netty.util.IllegalReferenceCountException: refCnt: 0, decrement: 1\r\n\tat io.netty.util.internal.ReferenceCountUpdater.toLiveRealRefCnt(ReferenceCountUpdater.java:74)\r\n\tat io.netty.util.internal.ReferenceCountUpdater.release(ReferenceCountUpdater.java:138)\r\n\tat io.netty.buffer.AbstractReferenceCountedByteBuf.release(AbstractReferenceCountedByteBuf.java:100)\r\n\tat io.netty.handler.codec.http.DefaultFullHttpRequest.release(DefaultFullHttpRequest.java:102)\r\n\tat io.netty.util.ReferenceCountUtil.release(ReferenceCountUtil.java:88)\r\n\tat io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:91)\r\n\t... 111 more\r\n\r\nio.netty.channel.unix.Errors$NativeIoException: writevAddresses(..) failed: Connection reset by peer\r\n```\r\n\r\n## Possible Solution\r\nFrom what I understand from the source code for SimpleDequePool.java, the method `drainLoop()` just incremented WIP while checking the (WIP.getAndIncrement(this) == 0) condition and then decrementing WIP for itself.\r\n\r\nIf some exceptions occured during `drainLoop()`, it would fail to handle decrementing WIP, the further requests to drain() will never pass the below if condition.\r\n\r\n```java\r\nvoid drain() {\r\n    if (WIP.getAndIncrement(this) == 0) {\r\n        drainLoop();\r\n    }\r\n}\r\n```\r\n\r\nSo I think it'd be better to implement fallback to decrement the WIP in case something wrong happen during `drainLoop`.\r\n\r\n## Your Environment\r\nreactor-netty: 0.9.14.RELEASE\r\nnetty: 4.1.51.Final\r\nJVM version: openjdk version \"11.0.4\"\r\nOS and version: 4.19.118-1.el7.centos.x86_64 \r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/reactor/reactor-pool/issues/118/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/reactor/reactor-pool/issues/118/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  },
  {
    "url": "https://api.github.com/repos/reactor/reactor-pool/issues/88",
    "repository_url": "https://api.github.com/repos/reactor/reactor-pool",
    "labels_url": "https://api.github.com/repos/reactor/reactor-pool/issues/88/labels{/name}",
    "comments_url": "https://api.github.com/repos/reactor/reactor-pool/issues/88/comments",
    "events_url": "https://api.github.com/repos/reactor/reactor-pool/issues/88/events",
    "html_url": "https://github.com/reactor/reactor-pool/issues/88",
    "id": 663638290,
    "node_id": "MDU6SXNzdWU2NjM2MzgyOTA=",
    "number": 88,
    "title": "Add a `PriorityQueue`-for-idle-resources variant",
    "user": {
      "login": "simonbasle",
      "id": 6986166,
      "node_id": "MDQ6VXNlcjY5ODYxNjY=",
      "avatar_url": "https://avatars.githubusercontent.com/u/6986166?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/simonbasle",
      "html_url": "https://github.com/simonbasle",
      "followers_url": "https://api.github.com/users/simonbasle/followers",
      "following_url": "https://api.github.com/users/simonbasle/following{/other_user}",
      "gists_url": "https://api.github.com/users/simonbasle/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/simonbasle/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/simonbasle/subscriptions",
      "organizations_url": "https://api.github.com/users/simonbasle/orgs",
      "repos_url": "https://api.github.com/users/simonbasle/repos",
      "events_url": "https://api.github.com/users/simonbasle/events{/privacy}",
      "received_events_url": "https://api.github.com/users/simonbasle/received_events",
      "type": "User",
      "user_view_type": "public",
      "site_admin": false
    },
    "labels": [
      {
        "id": 1096290894,
        "node_id": "MDU6TGFiZWwxMDk2MjkwODk0",
        "url": "https://api.github.com/repos/reactor/reactor-pool/labels/type/enhancement",
        "name": "type/enhancement",
        "color": "d4c5f9",
        "default": false,
        "description": "A general enhancement"
      },
      {
        "id": 1323599754,
        "node_id": "MDU6TGFiZWwxMzIzNTk5NzU0",
        "url": "https://api.github.com/repos/reactor/reactor-pool/labels/for/user-attention",
        "name": "for/user-attention",
        "color": "c5def5",
        "default": false,
        "description": "This issue needs user attention (feedback, rework, etc...)"
      },
      {
        "id": 1481553054,
        "node_id": "MDU6TGFiZWwxNDgxNTUzMDU0",
        "url": "https://api.github.com/repos/reactor/reactor-pool/labels/status/need-investigation",
        "name": "status/need-investigation",
        "color": "fef2c0",
        "default": false,
        "description": "This needs more in-depth investigation"
      }
    ],
    "state": "open",
    "locked": false,
    "assignee": null,
    "assignees": [],
    "milestone": {
      "url": "https://api.github.com/repos/reactor/reactor-pool/milestones/13",
      "html_url": "https://github.com/reactor/reactor-pool/milestone/13",
      "labels_url": "https://api.github.com/repos/reactor/reactor-pool/milestones/13/labels",
      "id": 5688752,
      "node_id": "MDk6TWlsZXN0b25lNTY4ODc1Mg==",
      "number": 13,
      "title": "Backburner",
      "description": null,
      "creator": {
        "login": "simonbasle",
        "id": 6986166,
        "node_id": "MDQ6VXNlcjY5ODYxNjY=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6986166?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/simonbasle",
        "html_url": "https://github.com/simonbasle",
        "followers_url": "https://api.github.com/users/simonbasle/followers",
        "following_url": "https://api.github.com/users/simonbasle/following{/other_user}",
        "gists_url": "https://api.github.com/users/simonbasle/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/simonbasle/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/simonbasle/subscriptions",
        "organizations_url": "https://api.github.com/users/simonbasle/orgs",
        "repos_url": "https://api.github.com/users/simonbasle/repos",
        "events_url": "https://api.github.com/users/simonbasle/events{/privacy}",
        "received_events_url": "https://api.github.com/users/simonbasle/received_events",
        "type": "User",
        "user_view_type": "public",
        "site_admin": false
      },
      "open_issues": 2,
      "closed_issues": 0,
      "state": "open",
      "created_at": "2020-07-22T09:46:19Z",
      "updated_at": "2024-06-03T09:20:47Z",
      "due_on": null,
      "closed_at": null
    },
    "comments": 1,
    "created_at": "2020-07-22T10:06:20Z",
    "updated_at": "2022-09-01T16:38:55Z",
    "closed_at": null,
    "author_association": "CONTRIBUTOR",
    "type": null,
    "active_lock_reason": null,
    "sub_issues_summary": {
      "total": 0,
      "completed": 0,
      "percent_completed": 0
    },
    "body": "## Motivation\r\nAn extension of #87 where other criteria than Least|Most-Recently-Used would be possible for polling order of idle resources (ie. created oldest).\r\n\r\nThe **Priority Queue** opens up more usages since a `Comparator<PooledRef>` can be used. For instance, one could prioritize youngest/oldest resources (in terms of creation time, independently of when it was last released) or by number of acquisitions. As long as the \"priority\" is not changing after insertion.\r\n\r\nThis implies:\r\n - Adding accessors for the `PooledRef` release timestamp (and creation timestamp): as \"age\" is a function of time and so is too dynamic for a priority => a timestamp is more absolute\r\n - Possible performance loss: the `PriorityQueue` interface relying on `Comparator`, implementations may be less efficient than simple baked-in fifo/lifo in `Deque` implementations\r\n\r\nAt the same time, it would better support maintaining order when polling-and-reinserting, which could help recover from some CAS failures.\r\n\r\n## Desired solution\r\nAn efficient **Priority Queue** implementation would be necessary, but the JDK only provides a binary-heap implementation **that is not thread-safe** (`PriorityQueue`) or a thread safe version **that relies heavily on blocking/locks** (`PriorityBlockingQueue`).\r\n\r\n## Considered alternatives\r\nImplement one of the papers below.\r\n\r\n## Additional context\r\nTo our knowledge, no efficient lock-free implementation of **Priority Queue** exist in Java.\r\nFor reference, here are a few recent papers on concurrent priority queues:\r\n - [\"A Practical, Scalable, Relaxed Priority Queue.\"](http://sss.cse.lehigh.edu/files/pubs/CR-ICPP-2019.pdf) or ZMSQ (T Zhou, M Michael, M Spear - 2019)\r\n - [\"CBPQ: High Performance Lock-Free Priority Queue.\"](http://www.cs.technion.ac.il/~erez/Papers/cbpq-paper-l.pdf) (Braginsky A, Cohen N, Petrank E. - 2016)\r\n -  [\"The spraylist: A scalable relaxed priority queue.\"](https://dspace.mit.edu/bitstream/handle/1721.1/101058/Shavit_The%20spraylist.pdf?sequence=1&isAllowed=y) (Alistarh, Dan, et al. - 2015)\r\n - [\"A skiplist-based concurrent priority queue with minimal memory contention.\"](http://www-sop.inria.fr/members/Nicolas.Nisse/talks/session5/pq.pdf) (Lind√©n, Jonatan, and Bengt Jonsson - 2013)\r\n",
    "closed_by": null,
    "reactions": {
      "url": "https://api.github.com/repos/reactor/reactor-pool/issues/88/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "timeline_url": "https://api.github.com/repos/reactor/reactor-pool/issues/88/timeline",
    "performed_via_github_app": null,
    "state_reason": null
  }
]